lr
load("../output/svm.fit.LBP.Rdata")
lr
feature = 'lbp'
source("../lib/train_v2.R")
source("../lib/test_v2.R")
source("../lib/train_test_split.R")
source("../lib/train.R")
source("../lib/test.R")
source("../lib/train_test_split.R")
library(caret)
library(gbm)
library(e1071)
library(randomForest)
library(nnet)
df = train_test_split(feature_name = feature)
df_train = df$df_train
df_test = df$df_test
lr = train_lr(df_train)
train_lr_accuracy = mean(test(lr,df_train) == df_train$Label)
test_lr_accuracy = mean(test(lr,df_test) == df_test$Label)
lr_time = lr$time
save(lr, '../output/lr.fit.LBP.Rdata')
save(lr, file = '../output/lr.fit.LBP.Rdata')
gbm = train_gbm(df_train)
baseline.test.pre = test(baseline.model, sift_test)
save(gbm, file = '../output/gbm.fit.LBP.Rdata')
rf = train_rf(df_train)
save(rf, file = '../output/rf.fit.LBP.Rdata')
svm = train_svm(df_train)
save(svm, file = '../output/svm.fit.LBP.Rdata')
load("../output/lr.fit.LBP.Rdata")
load("../output/rf.fit.LBP.Rdata")
load("../output/gbm.fit.LBP.Rdata")
load("../output/baseline.result.Rdata")
packages.used=c("caret","gbm", "e1071", "DMwR", "nnet", "randomForest","OpenImageR","DT", "caTools", "EBImage", "mxnet", "pbapply", "ggthemes")
# check packages that need to be installed.
packages.needed=setdiff(packages.used,
intersect(installed.packages()[,1],
packages.used))
# install additional packages
if(length(packages.needed)>0){
install.packages(packages.needed, dependencies = TRUE)
}
library(caret)
library(gbm)
library(e1071)
library(DMwR)
library(randomForest)
library(nnet)
library(OpenImageR)
library(DT)
library(caTools)
library(EBImage)
library(mxnet)
library(pbapply)
library(ggthemes)
source("../lib/train.R")
source("../lib/test.R")
source("../lib/train_test_split.R")
load("../output/baseline.result.Rdata")
baseline.time = baseline.result[[4]]
baseline.time
baseline.accuracy = 1 - baseline.result[[3]]
print(paste0("The accuracy rate of baseline model is ", baseline.accuracy))
# Classifications                   Accuracy Rate
# Sift + GBM                              ~73%
# Sift + Logistic Regression              ~71%
# Sift + Random Forest                    ~73%
# Sift + SVM                              ~33%
load("../output/lbp.result.Rdata")
lbp.result
load("../output/hog.para.accuracy.Rdata")
hog.para.accuracy
df = train_test_split("hog510")
HoG_train = df$df_train
HoG_test = df$df_test
load("../output/hog.result.Rdata")
hog.result
load(file = '../output/cnn.test.Rdata')
df_cnn
load("../output/lbp.result.Rdata")
load("../output/hog.result.Rdata")
load("../output/baseline.result.Rdata")
lbp.result$Feature<-rep("LBP",ncol(lbp.result))
hog.result$Feature<-rep("HoG",ncol(hog.result))
comp<-rbind(lbp.result,hog.result)
comp<-comp[,c(1,5,2,3,4)]
comp[,1] = as.character(comp[,1])
# round the accuracy rate and running time
comp$Test_accuracy <- round(comp$Test_accuracy,3)
comp$Running_Time <- round(comp$Running_Time,3)
par(mfrow=c(1,2))
ggplot(data=comp, aes(x=Model,y=Test_accuracy,color=Feature,fill=Feature)) +
geom_bar(stat="identity", position=position_dodge(), width = 0.4)+
geom_text(aes(label=Test_accuracy),color="Black",hjust=-0.2, position = position_dodge(0.5))+
theme_bw()+
scale_y_continuous(limits = c(0,1))+
#theme_solarized(light = T)+
coord_flip()
ggplot(data=comp, aes(x=Model,y=Running_Time,color=Feature,fill=Feature)) +
geom_bar(stat = "identity", position = position_dodge(), width = 0.4)+
geom_text(aes(label=Running_Time),color="Black",hjust=-0.1, position = position_dodge(0.5))+
theme_bw()+
scale_y_continuous(limits = c(0,150))+
ylab("Running Time(secs)")+
#theme_solarized(light = T)+
coord_flip()
comp<-rbind(comp,c("GBM","Sift",1-baseline.result[[2]],1-baseline.result[[3]],baseline.result[[4]]))
comp<-rbind(comp,c("CNN","CNN",0.963, 0.842,1924))
datatable(comp)
df_test = read.csv("../output/lbp_test.csv", header = F)
label_test = read.csv('../data/label_test.csv', header = T)
sift_test = read.csv('../data/sift_test.csv', header = T)[,-1]
load("../output/lr.fit.LBP.Rdata")
load("../output/rf.fit.LBP.Rdata")
load("../output/baseline.result.Rdata")
baseline.model = list(fit = baseline.result[[1]])
baseline.test.pre = test(baseline.model, sift_test)
test_lr = test(lr, df_test)
test_rf = test(rf, df_test)
test_svm = test(svm, df_test)
load("../output/svm.fit.LBP.Rdata")
test_svm = test(svm, df_test)
test_gbm = test(gbm, df_test)
test_gbm = test_gbm(gbm, df_test)
View(label_test)
baseline.result
baseline.test.pre = test_gbm(baseline.model, sift_test)
source("../lib/test.R")
baseline.test.pre = test_gbm(baseline.model, sift_test)
baseline.model = list(fit = baseline.result[[1]])
baseline.test.pre = test_gbm(baseline.model, sift_test)
View(sift_test)
baseline.test.pre = test_gbm(baseline.model, sift_test)
View(label_test)
baseline.test.pre = test(baseline.model, sift_test)
baseline.test.pre = predict(baseline.model$fit, sift_test)
baseline.model
baseline.result[[1]]
baseline.test.pre = predict(baseline.result[[1]], sift_test)
load("../output/gbm.fit.model.Rdata")
baseline.test.pre = predict(gbm.fit, sift_test)
sift_test = read.csv('../data/sift_test.csv', header = T)
View(sift_test)
sift_test$Image_Number = c(1:3000)
load("../output/baseline.result.Rdata")
baseline.model = list(fit = baseline.result[[1]])
baseline.test.pre = predict(baseline.result[[1]], sift_test)
df = train_test_split('lbp')
test_lr_prediction = test(lr, df_test)
test_lr_prediction
write.csv(test_lr_prediction,"../output/cnn_test_prediction.csv")
load("../output/gbm.fit.LBP.Rdata")
test_lr_prediction = test_gbm(gbm, df_test)
test_lr_prediction
write.csv(test_lr_prediction,"../output/lr_test_prediction.csv")
write.csv(test_gbm_prediction,"../output/gbm_test_prediction.csv")
test_gbm_prediction = test_gbm(gbm, df_test)
write.csv(test_gbm_prediction,"../output/gbm_test_prediction.csv")
load("../output/baseline.result.Rdata")
baseline.model = list(fit = baseline.result[[1]])
baseline.test.pre = predict(baseline.model, sift_test)
label_test = data.frame(X = c(1:3000), 'GBM', 'SVM', 'Random Forest', 'Logistic Regression', 'Neural Networks')
View(label_test)
test_gbm
packages.used=c("caret","gbm", "e1071", "DMwR", "nnet", "randomForest","OpenImageR","DT", "caTools", "EBImage", "mxnet", "pbapply", "ggthemes")
# check packages that need to be installed.
packages.needed=setdiff(packages.used,
intersect(installed.packages()[,1],
packages.used))
# install additional packages
if(length(packages.needed)>0){
install.packages(packages.needed, dependencies = TRUE)
}
library(caret)
library(gbm)
library(e1071)
library(DMwR)
library(randomForest)
library(nnet)
library(OpenImageR)
library(DT)
library(caTools)
library(EBImage)
library(mxnet)
library(pbapply)
library(ggthemes)
source("../lib/train.R")
source("../lib/test.R")
source("../lib/train_test_split.R")
load("../output/baseline.result.Rdata")
baseline.time = baseline.result[[4]]
baseline.time
baseline.accuracy = 1 - baseline.result[[3]]
print(paste0("The accuracy rate of baseline model is ", baseline.accuracy))
# Classifications                   Accuracy Rate
# Sift + GBM                              ~73%
# Sift + Logistic Regression              ~71%
# Sift + Random Forest                    ~73%
# Sift + SVM                              ~33%
load("../output/lbp.result.Rdata")
lbp.result
load("../output/hog.para.accuracy.Rdata")
hog.para.accuracy
df = train_test_split("hog510")
HoG_train = df$df_train
HoG_test = df$df_test
load("../output/hog.result.Rdata")
hog.result
load("../output/lbp.result.Rdata")
load("../output/hog.result.Rdata")
load("../output/baseline.result.Rdata")
lbp.result$Feature<-rep("LBP",ncol(lbp.result))
hog.result$Feature<-rep("HoG",ncol(hog.result))
comp<-rbind(lbp.result,hog.result)
comp<-comp[,c(1,5,2,3,4)]
comp[,1] = as.character(comp[,1])
# round the accuracy rate and running time
comp$Test_accuracy <- round(comp$Test_accuracy,3)
comp$Running_Time <- round(comp$Running_Time,3)
par(mfrow=c(1,2))
ggplot(data=comp, aes(x=Model,y=Test_accuracy,color=Feature,fill=Feature)) +
geom_bar(stat="identity", position=position_dodge(), width = 0.4)+
geom_text(aes(label=Test_accuracy),color="Black",hjust=-0.2, position = position_dodge(0.5))+
theme_bw()+
scale_y_continuous(limits = c(0,1))+
#theme_solarized(light = T)+
coord_flip()
ggplot(data=comp, aes(x=Model,y=Running_Time,color=Feature,fill=Feature)) +
geom_bar(stat = "identity", position = position_dodge(), width = 0.4)+
geom_text(aes(label=Running_Time),color="Black",hjust=-0.1, position = position_dodge(0.5))+
theme_bw()+
scale_y_continuous(limits = c(0,150))+
ylab("Running Time(secs)")+
#theme_solarized(light = T)+
coord_flip()
comp<-rbind(comp,c("GBM","Sift",1-baseline.result[[2]],1-baseline.result[[3]],baseline.result[[4]]))
comp<-rbind(comp,c("CNN","CNN",0.963, 0.842,1924))
datatable(comp)
df_test = read.csv("../output/lbp_test.csv", header = F)
sift_test = read.csv('../data/sift_test.csv', header = T)
load("../output/lr.fit.LBP.Rdata")
load("../output/rf.fit.LBP.Rdata")
load("../output/svm.fit.LBP.Rdata")
load("../output/gbm.fit.LBP.Rdata")
load("../output/baseline.result.Rdata")
baseline.model = list(fit = baseline.result[[1]])
baseline.test.pre = predict(baseline.model, sift_test)
test_lr = test(lr, df_test)
test_rf = test(rf, df_test)
test_svm = test(svm, df_test)
test_gbm = test_gbm(gbm, df_test)
baseline.result
label_test = read.csv("../output/cnn_test_prediction.csv", header = T)
label_test = data.frame(X = c(1:3000), 'GBM' = test_gbm, 'SVM', 'Random Forest', 'Logistic Regression', 'Neural Networks')
View(label_test)
label_test = read.csv("../data/test_label", header = T)
label_test = read.csv("../data/label_test", header = T)
label_test = read.csv("../data/label_test.csv", header = T)
View(label_test)
test_cnn = read.csv('../output/cnn_test_prediction.csv')
label_test = data.frame(X = c(1:3000), 'GBM' = test_gbm, 'SVM' = test_svm, 'Random Forest' = test_rf 'Logistic Regression' = test_lr, 'Neural Networks' = test_cnn[,2])
test_cnn[,2]
label_test = data.frame(X = c(1:3000), 'GBM' = test_gbm, 'SVM' = test_svm, 'Random Forest' = test_rf 'Logistic Regression' = test_lr)
test_lr = test(lr, df_test)
test_rf = test(rf, df_test)
label_test = data.frame(X = c(1:3000), 'GBM' = test_gbm, 'SVM' = test_svm, 'Random Forest' = test_rf 'Logistic Regression' = test_lr,, 'Neural Networks' = test_cnn[,2])
test_gbm
test_cnn[,2]
label_test = data.frame(X = c(1:3000), 'GBM' = test_gbm, 'SVM' = test_svm, 'Random Forest' = test_rf 'Logistic Regression' = test_lr,'Neural Networks' = test_cnn[,2])
label_test = data.frame(X = c(1:3000), 'GBM' = test_gbm, 'SVM' = test_svm, 'Random Forest' = test_rf 'Logistic Regression' = test_lr,'Neural Networks' = as.numeric(test_cnn[,2]))
label_test = data.frame(X = c(1:3000), 'GBM' = test_gbm, 'SVM' = test_svm, 'Random Forest' = test_rf 'Logistic Regression' = test_lr,'Neural Networks' = as.vector(test_cnn[,2]))
label_test = data.frame(X = c(1:3000), 'GBM' = test_gbm, 'SVM' = test_svm, 'Random Forest' = test_rf 'Logistic Regression' = test_lr)
label_test = data.frame(X = c(1:3000), 'GBM' = test_gbm, 'SVM' = test_svm, 'Random Forest' = test_rf, 'Logistic Regression' = test_lr, 'Neural Networks' = as.vector(test_cnn[,2]))
View(label_test)
write.csv(label_test_baseline, 'label_test_baseline.csv',row.names = F)
label_test_baseline = data.frame(X = c(1:3000), 'baseline' = test_gbm)
write.csv(label_test_baseline, 'label_test_baseline.csv',row.names = F)
label_test = data.frame(X = c(1:3000), 'GBM' = test_gbm, 'SVM' = test_svm, 'Random Forest' = test_rf, 'Logistic Regression' = test_lr, 'Neural Networks' = as.vector(test_cnn[,2]))
View(label_test)
label_test_all = data.frame(X = c(1:3000), 'GBM' = test_gbm, 'SVM' = test_svm, 'Random Forest' = test_rf, 'Logistic Regression' = test_lr, 'Neural Networks' = as.vector(test_cnn[,2]))
write.csv(label_test_all, 'label_test_baseline.csv',row.names = F)
write.csv(label_test_baseline, 'label_test_baseline.csv',row.names = F)
write.csv(label_test_all, 'label_test_all.csv',row.names = F)
mv_df = read.csv('../output/all_train_prediction.csv', header = T)
View(mv_df)
mv_label = mv_df$combo_train_prediction
df = train_test_split('lbp')
mean(mv_label == df_test)
load("../output/svm.fit.LBP.Rdata")
svm
df = train_test_split('lbp')
svm_result = test(svm, df$df_test)
svm_result
svm_train_prediction = test(svm, df$df_test)
write.csv(svm_train_prediction, '../output/svm_train_prediction.csv', row.names = F)
cnn_train_prediction = read.csv("../output/cnn_train_prediction.csv")$x
setwd("~/Documents/GitHub/Fall2017-project3-fall2017-project3-grp4/doc")
cnn_train_prediction = read.csv("../output/cnn_train_prediction.csv")$x
cnn_train_prediction = read.csv("../output/svm_train_prediction.csv")$x
lr_train_prediction = read.csv("../output/lr_train_prediction.csv")$x
gbm_train_prediction = read.csv("../output/gbm_train_prediction.csv")$x
all_train=data.frame(cnn_train_prediction,lr_train_prediction,gbm_train_prediction)
for (i in 1:3000){
if (all_train[i,1]==all_train[i,2]){
all_train[i,4]=all_train[i,1]
} else if (all_train[i,1]==all_train[i,3]){
all_train[i,4]=all_train[i,1]
} else if (all_train[i,2]==all_train[i,3]){
all_train[i,4]=all_train[i,3]
} else{
all_train[i,4]=all_train[i,2]
}
}
df=train_test_split('lbp')
mean(all_train$V4 == df_test)
View(all_train)
df_test
View(df_test)
a = df$df_train
b = df$df_test
df = train_test_split('lbp')
svm_pre = test(svm,df$df_test)
svm_pre
gbm_pre = test(gbm,df$df_test)
gbm_pre = test.gbm(gbm,df$df_test)
source("../lib/test.R")
gbm_pre = test_gbm(gbm,df$df_test)
all_train=data.frame(svm_pre,lr_pre,gbm_pre)
lr_pre = test(lr,df$df_test)
all_train=data.frame(svm_pre,lr_pre,gbm_pre)
for (i in 1:600){
if (all_train[i,1]==all_train[i,2]){
all_train[i,4]=all_train[i,1]
} else if (all_train[i,1]==all_train[i,3]){
all_train[i,4]=all_train[i,1]
} else if (all_train[i,2]==all_train[i,3]){
all_train[i,4]=all_train[i,3]
} else{
all_train[i,4]=all_train[i,2]
}
}
mean(all_train$V4 == df_test)
mean(all_train$V4 == df$df_test)
all_train$V4
mean(all_train$V4 == df$df_test)
df$df_test
b = df$df_test
mean(all_train$V4 == df$df_test$Label)
load("../output/lbp.result.Rdata")
load("../output/hog.result.Rdata")
load("../output/baseline.result.Rdata")
lbp.result$Feature<-rep("LBP",ncol(lbp.result))
hog.result$Feature<-rep("HoG",ncol(hog.result))
comp<-rbind(lbp.result,hog.result)
View(comp)
print(paste0("The test accuracy of the majority vote model is ", mean(all_train$V4 == df$df_test$Label)))
colnames(comp)
test_svm
all_train=data.frame(test_svm,test_lr,test_gbm)
all_train=data.frame(test_svm,test_lr,test_gbm)
test_svm
test_gbm_1 = test_gbm(gbm, df_test)
test_gbm_1
all_train=data.frame(test_svm,test_lr,test_gbm_1)
for (i in 1:3000){
if (all_train[i,1]==all_train[i,2]){
all_train[i,4]=all_train[i,1]
} else if (all_train[i,1]==all_train[i,3]){
all_train[i,4]=all_train[i,1]
} else if (all_train[i,2]==all_train[i,3]){
all_train[i,4]=all_train[i,3]
} else{
all_train[i,4]=all_train[i,2]
}
}
packages.used=c("caret","gbm", "e1071", "DMwR", "nnet", "randomForest","OpenImageR","DT", "caTools", "EBImage", "mxnet", "pbapply", "ggthemes")
# check packages that need to be installed.
packages.needed=setdiff(packages.used,
intersect(installed.packages()[,1],
packages.used))
# install additional packages
if(length(packages.needed)>0){
install.packages(packages.needed, dependencies = TRUE)
}
library(caret)
library(gbm)
library(e1071)
library(DMwR)
library(randomForest)
library(nnet)
library(OpenImageR)
library(DT)
library(caTools)
library(EBImage)
library(mxnet)
library(pbapply)
library(ggthemes)
source("../lib/train.R")
source("../lib/test.R")
source("../lib/train_test_split.R")
load("../output/baseline.result.Rdata")
baseline.time = baseline.result[[4]]
baseline.time
baseline.accuracy = 1 - baseline.result[[3]]
print(paste0("The accuracy rate of baseline model is ", baseline.accuracy))
# Classifications                   Accuracy Rate
# Sift + GBM                              ~73%
# Sift + Logistic Regression              ~71%
# Sift + Random Forest                    ~73%
# Sift + SVM                              ~33%
load("../output/lbp.result.Rdata")
lbp.result
load("../output/hog.para.accuracy.Rdata")
hog.para.accuracy
df = train_test_split("hog510")
HoG_train = df$df_train
HoG_test = df$df_test
load("../output/hog.result.Rdata")
hog.result
load("../output/lr.fit.LBP.Rdata")
load("../output/svm.fit.LBP.Rdata")
load("../output/gbm.fit.LBP.Rdata")
# Here is the code we use to create majority vote matrix
df = train_test_split('lbp')
svm_pre = test(svm,df$df_test)
lr_pre = test(lr,df$df_test)
gbm_pre = test_gbm(gbm,df$df_test)
all_train=data.frame(svm_pre,lr_pre,gbm_pre)
for (i in 1:600){
if (all_train[i,1]==all_train[i,2]){
all_train[i,4]=all_train[i,1]
} else if (all_train[i,1]==all_train[i,3]){
all_train[i,4]=all_train[i,1]
} else if (all_train[i,2]==all_train[i,3]){
all_train[i,4]=all_train[i,3]
} else{
all_train[i,4]=all_train[i,2]
}
}
print(paste0("The test accuracy of the majority vote model is ", mean(all_train$V4 == df$df_test$Label)))
load("../output/lbp.result.Rdata")
load("../output/hog.result.Rdata")
load("../output/baseline.result.Rdata")
lbp.result$Feature<-rep("LBP",ncol(lbp.result))
hog.result$Feature<-rep("HoG",ncol(hog.result))
comp<-rbind(lbp.result,hog.result)
comp<-comp[,c(1,5,2,3,4)]
comp[,1] = as.character(comp[,1])
# round the accuracy rate and running time
comp$Test_accuracy <- round(comp$Test_accuracy,3)
comp$Running_Time <- round(comp$Running_Time,3)
par(mfrow=c(1,2))
ggplot(data=comp, aes(x=Model,y=Test_accuracy,color=Feature,fill=Feature)) +
geom_bar(stat="identity", position=position_dodge(), width = 0.4)+
geom_text(aes(label=Test_accuracy),color="Black",hjust=-0.2, position = position_dodge(0.5))+
theme_bw()+
scale_y_continuous(limits = c(0,1))+
#theme_solarized(light = T)+
coord_flip()
ggplot(data=comp, aes(x=Model,y=Running_Time,color=Feature,fill=Feature)) +
geom_bar(stat = "identity", position = position_dodge(), width = 0.4)+
geom_text(aes(label=Running_Time),color="Black",hjust=-0.1, position = position_dodge(0.5))+
theme_bw()+
scale_y_continuous(limits = c(0,150))+
ylab("Running Time(secs)")+
#theme_solarized(light = T)+
coord_flip()
comp<-rbind(comp,c("GBM","Sift",1-baseline.result[[2]],1-baseline.result[[3]],baseline.result[[4]]))
comp<-rbind(comp,c("CNN","CNN",0.963, 0.842,1924))
datatable(comp)
comp
df_test = read.csv("../output/lbp_test.csv", header = F)
test_cnn = read.csv('../output/cnn_test_prediction.csv')
#Get the label of the baseline model's prediction
label_test_baseline = data.frame(X = c(1:3000), 'baseline' = test_gbm)
label_test_baseline = data.frame(X = c(1:3000), 'baseline' = test_gbm_1)
test_gbm_1
sift_test = read.csv('../data/sift_test.csv', header = T)
load("../output/lr.fit.LBP.Rdata")
load("../output/rf.fit.LBP.Rdata")
load("../output/svm.fit.LBP.Rdata")
load("../output/gbm.fit.LBP.Rdata")
load("../output/baseline.result.Rdata")
baseline.model = list(fit = baseline.result[[1]])
baseline.test.pre = predict(baseline.model, sift_test)
test_lr = test(lr, df_test)
test_rf = test(rf, df_test)
test_svm = test(svm, df_test)
test_gbm_1 = test_gbm(gbm, df_test)
test_cnn = read.csv('../output/cnn_test_prediction.csv')
#Get the label of the baseline model's prediction
label_test_baseline = data.frame(X = c(1:3000), 'baseline' = test_gbm_1)
write.csv(label_test_baseline, 'label_test_baseline.csv',row.names = F)
#Get the label of other classification model's prediction
all_train=data.frame(test_svm,test_lr,test_gbm_1)
for (i in 1:3000){
if (all_train[i,1]==all_train[i,2]){
all_train[i,4]=all_train[i,1]
} else if (all_train[i,1]==all_train[i,3]){
all_train[i,4]=all_train[i,1]
} else if (all_train[i,2]==all_train[i,3]){
all_train[i,4]=all_train[i,3]
} else{
all_train[i,4]=all_train[i,2]
}
}
label_test_all = data.frame(X = c(1:3000), 'GBM' = test_gbm_1, 'SVM' = test_svm, 'Random Forest' = test_rf, 'Logistic Regression' = test_lr, 'Neural Networks' = as.vector(test_cnn[,2]), 'majority_vote' = all_train$V4)
write.csv(label_test_all, 'label_test_all.csv',row.names = F)
label_test_all = data.frame(X = c(1:3000), 'GBM' = test_gbm_1, 'SVM' = test_svm, 'Random Forest' = test_rf, 'Logistic Regression' = test_lr, 'Neural Networks' = as.vector(test_cnn[,2]), 'majority_vote' = all_train$V4)
View(label_test_all)
